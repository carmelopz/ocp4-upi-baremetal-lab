= Openshift 4 backup

The Openshift 4 backup generates 2 different files with the date when it was performed.

[source,bash]
----
snapshot_2020-09-24_123046.db
static_kuberesources_2020-09-24_123046.tar.gz
----

The `+.db+` file is a snapshot of the etcd and the `+.tar.gz+` contains the `static pods` of the control plane (etcd, api server, controller manager and scheduler) with their respective certificates and private keys. The backup that is made in a master contains the information of all masters, so it is only necessary to make it in a single master.

To do this from within Openshift we will create a `CronJob` that runs every day at 3:30 in the morning and saves the files in a PVC.

1. Create `+etcd-backup+` namespace.

[source,bash]
----
$ oc create ns etcd-backup
----

2. Create a PVC to store the backup files (choose size based on etcd size and retention period).

[source,bash]
----
$ oc get pvc etcd-backup-files -n etcd-backup

NAME                STATUS   VOLUME              CAPACITY   ACCESS MODES   STORAGECLASS   AGE
etcd-backup-files   Bound    etcd-backup-files   5Gi        RWX                           8s
----

3. Create RBAC rules. The backup is done using the root user from a master, therefore the SA must use the `+priviledged SCC+`.

[source,bash]
----
$ oc apply -f etcd-backup-rbac.yml -n etcd-backup

$ oc get sa etcd-backup -n etcd-backup
NAME          SECRETS   AGE
etcd-backup   2         5s

$ oc get role use-privileged-scc -n etcd-backup
NAME                 AGE
use-privileged-scc   20s

$ oc get rolebinding etcd-backup-sa-privileged -n etcd-backup
NAME                        AGE
etcd-backup-sa-privileged   34s
----

4. Create the `CronJob` to perform the backup periodically (change schedule if needed).

[source,bash]
----
$ oc apply -f etcd-backup-cronjob.yml -n etcd-backup

$ oc get cronjob etcd-backup -n etcd-backup
NAME          SCHEDULE     SUSPEND   ACTIVE   LAST SCHEDULE   AGE
etcd-backup   30 3 * * *   False     0        <none>          3s
----

5. Test the backup result running a `+Job+` from the `+CronJob+`.

[source,bash]
----
# oc client < 4.5
$ oc create job --from=cronjob/etcd-backup etcd-backup-manual-"$(date +%s)" --dry-run -o yaml |\
    sed 's/apps\/v1/batch\/v1beta1/' | oc create -f -

$ # oc client > 4.4
oc create job --from=cronjob/etcd-backup etcd-backup-manual-"$(date +%s)"

$ oc logs etcd-backup-manual-1600956702-6w5hr -n etcd-backup
0a4704d82b8682c34f09b05032641942cfcc51519be4318d53b4658181de5fb4
etcdctl version: 3.3.22
API version: 3.3
found latest kube-apiserver-pod: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-8
found latest kube-controller-manager-pod: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-8
found latest kube-scheduler-pod: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-9
found latest etcd-pod: /etc/kubernetes/static-pod-resources/etcd-pod-2
2020-09-24 14:11:49.091032 I | clientv3: opened snapshot stream; downloading
2020-09-24 14:11:50.824565 I | clientv3: completed snapshot read; closing
Snapshot saved at /home/core/assets/backup/snapshot_2020-09-24_141148.db
snapshot db and kube resources are successfully saved to /home/core/assets/backup
sending incremental file list
snapshot_2020-09-24_141148.db
static_kuberesources_2020-09-24_141148.tar.gz

sent 125,528,531 bytes  received 54 bytes  83,685,723.33 bytes/sec
total size is 125,497,687  speedup is 1.00
----

6. Verify if the backup has been correctly created in the storage backend.
